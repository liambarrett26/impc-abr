# ContrastiveVAE-DEC Model Architecture Configuration - LARGE VERSION
# Configuration for audiometric phenotype clustering in mouse genetic data
# This version has significantly increased model capacity for better representation learning

# =============================================================================
# DATA SPECIFICATIONS
# =============================================================================
data:
  # Input feature dimensions
  abr_features: 6           # ABR thresholds (6, 12, 18, 24, 30 kHz + Click)
  metadata_features: 10     # Age, weight, sex, zygosity, etc.
  pca_features: 2           # PCA components from ABR data
  total_features: 18        # Total input dimensions

  # Feature groups for specialized processing
  audiometric_indices: [0, 1, 2, 3, 4, 5]  # ABR threshold indices
  continuous_indices: [6, 7, 16, 17]        # Age, weight, PCA components
  categorical_indices: [8, 9, 10, 11, 12, 13, 14, 15]  # Metadata categories

# =============================================================================
# ENCODER ARCHITECTURE - INCREASED CAPACITY
# =============================================================================
encoder:
  # Main encoder layers - MUCH DEEPER AND WIDER
  hidden_dims: [256, 128, 64]  # Was: [64, 32, 16] - 4x increase in first layer
  dropout_rate: 0.2             # Dropout for regularization
  activation: 'relu'            # Activation function

  # Frequency-aware attention mechanism - MORE HEADS AND DIMENSIONS
  attention:
    enabled: true
    head_dim: 32              # Was: 8 - 4x increase
    num_heads: 8              # Was: 2 - 4x increase
    dropout: 0.1              # Attention dropout rate

  # Feature-specific encoders - INCREASED CAPACITY
  abr_encoder:
    hidden_dim: 64            # Was: 16 - 4x increase
    use_batch_norm: true      # Batch normalization

  metadata_encoder:
    hidden_dim: 96            # Was: 24 - 4x increase
    embedding_dims:           # Increased embedding dimensions
      sex: 8                  # Was: 4
      zygosity: 8             # Was: 4
      genetic_background: 16  # Was: 8
      phenotyping_center: 24  # Was: 12

# =============================================================================
# LATENT SPACE CONFIGURATION - INCREASED DIMENSIONS
# =============================================================================
latent:
  latent_dim: 32              # Was: 10 - 3.2x increase for richer representations
  beta: 1.0                   # Beta parameter for beta-VAE (KL weight)

  # Variational parameters
  min_logvar: -10            # Minimum log variance (numerical stability)
  max_logvar: 10             # Maximum log variance (prevent explosion)

# =============================================================================
# DECODER ARCHITECTURE - MATCHING ENCODER INCREASE
# =============================================================================
decoder:
  # Main decoder layers (reverse of encoder)
  hidden_dims: [64, 128, 256] # Was: [16, 32, 64] - Matching encoder increase
  dropout_rate: 0.2           # Dropout for regularization
  activation: 'relu'          # Activation function

  # Output layer configuration
  output_activation: 'linear'  # Linear output for continuous values
  use_batch_norm: true        # Batch normalization

# =============================================================================
# CLUSTERING CONFIGURATION (DEC Component)
# =============================================================================
clustering:
  num_clusters: 12           # Number of phenotype clusters to discover
  cluster_init: 'kmeans'     # Cluster initialization method
  alpha: 1.0                 # Degrees of freedom for t-distribution

  # Cluster refinement
  update_interval: 50        # Epochs between cluster updates
  tolerance: 0.001           # Convergence tolerance

# =============================================================================
# CONTRASTIVE LEARNING - INCREASED PROJECTION DIMENSION
# =============================================================================
contrastive:
  temperature: 0.5           # Temperature parameter for contrastive loss
  projection_dim: 128        # Was: 64 - 2x increase for better separation

  # Data augmentation for contrastive pairs
  augmentation:
    noise_std: 0.05          # Gaussian noise standard deviation
    dropout_prob: 0.1        # Feature dropout probability
    magnitude_scale: 0.1     # Magnitude scaling factor

# =============================================================================
# LOSS FUNCTION WEIGHTS
# =============================================================================
loss_weights:
  # Primary objectives
  reconstruction: 1.0        # Reconstruction loss weight
  kl_divergence: 1.0        # VAE KL divergence weight
  clustering: 1.0           # DEC clustering loss weight
  contrastive: 0.5          # Contrastive learning weight

  # Regularization terms
  phenotype_consistency: 0.3  # Same-gene mice similarity
  frequency_smoothness: 0.1   # ABR frequency smoothness

  # Feature-specific reconstruction weights
  reconstruction_weights:
    abr: 2.0                # Higher weight for ABR features
    metadata: 1.0           # Standard weight for metadata
    pca: 1.5                # Medium weight for PCA components

# =============================================================================
# ARCHITECTURAL CHOICES
# =============================================================================
architecture:
  # Network initialization
  weight_init: 'xavier_uniform'  # Weight initialization method
  bias_init: 'zeros'            # Bias initialization

  # Normalization
  use_layer_norm: false         # Layer normalization (alternative to batch norm)
  use_spectral_norm: false      # Spectral normalization for stability

  # Advanced features
  residual_connections: false   # Skip connections in encoder/decoder
  gradient_clipping: 1.0        # Gradient clipping value (0 to disable)